# -*- coding: utf-8 -*-
"""TripletMarginLossMNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T2r6mcAaquaLQq78xHupI8cz92GWEA63
"""

# !pip install pytorch-metric-learning
# !pip install faiss-gpu

# !nvidia-smi

# !pip install gpustat

# !nvcc -V

# !pip install rich
# !pip install pytorch_lightning


# !pip install wandb

# import pytorch_lightning as pl


# class LitModel(pl.LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.l1 = nn.Linear(28 * 28, 10)

#     def forward(self, x):
#         return torch.relu(self.l1(x.view(x.size(0), -1)))

#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         y_hat = self(x)
#         loss = F.cross_entropy(y_hat, y)
#         return loss

#     def configure_optimizers(self):
#         return torch.optim.Adam(self.parameters(), lr=0.02)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from pytorch_lightning import LightningModule, Trainer
from rich.console import Console
### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###
from torchvision import datasets, transforms

from pytorch_metric_learning import distances, losses, miners, reducers, testers
from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning import Callback
from pytorch_lightning.loggers import CSVLogger
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.callbacks import QuantizationAwareTraining

import wandb

print = Console().print






class recognition_model(LightningModule):
    def __init__(self, trainset, testset, conv1_N = 64, conv1_filter = 3 , conv1_stride = 1, 
                 conv2_N = 128, conv2_filter = 5 , conv2_stride = 1 , dropout = 0.25, linear = [512, 256, 128], lr = 0.001):
        super(recognition_model, self).__init__()
        self.train_set = trainset
        self.test_set = testset
        self.lr = lr
        self.save_hyperparameters()
        self.conv1 = nn.Conv2d(1, conv1_N, conv1_filter, conv1_stride) # [N, 30, 30, 32]
        self.conv2 = nn.Conv2d(conv1_N, conv2_N, conv2_filter, conv2_stride) # [N, 28, 28, 64]
        self.dropout1 = nn.Dropout2d(dropout)
        self.dropout2 = nn.Dropout2d(dropout)
        self.fc1 = nn.Linear(56448, linear[0])
        self.fc2 = nn.Linear(linear[0], linear[1])
        self.fc3 = nn.Linear(linear[1], linear[2])                
        

        # metrics
        self.distance = distances.CosineSimilarity()
        self.reducer = reducers.ThresholdReducer(low=0)
        self.loss_func = losses.TripletMarginLoss(margin=0.2, distance=self.distance, reducer=self.reducer)
        # self.loss_func = losses.CircleLoss(m=0.4, gamma=80)
        self.mining_func = miners.TripletMarginMiner(
            margin=0.2, distance=self.distance, type_of_triplets="semihard"
        )
        self.accuracy_calculator = AccuracyCalculator(include=("precision_at_1",), k=1)

    def forward(self, x):
        x = self.conv1(x)# [N, 30, 30, 32]
        x = F.relu(x)# [N, 30, 30, 32]
        x = self.conv2(x)# [N, 28, 28, 64]
        x = F.relu(x)# [N, 28, 28, 64]
        x = F.avg_pool2d(x, 2, 1)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        # Console().rule(title=f"after flatten ===> {x.shape}", style="red on black")
        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)
        x = F.gelu(x)
        x = self.fc3(x)
        return x

    def get_all_embeddings(self, dataset, model):
        tester = testers.BaseTester()
        return tester.get_all_embeddings(dataset, model)

    def training_step(self, batch, batch_idx):

        data, labels = batch
        embeddings = self.forward(data)
        # Console().rule(title=f"EMBEDDINGS shape ===> {embeddings.shape}", style="bold magenta")
        indices_tuple = self.mining_func(embeddings, labels)
        # Console().rule(title=f"INDICES shape ===> {indices_tuple}", style="bold magenta")
        loss = self.loss_func(embeddings, labels, indices_tuple)
        # Console().print(f"epoch --> {self.current_epoch}\t\t Loss --> {loss.tolist()}", style="bold cyan")
        self.log(
            "train_loss" , loss.tolist()
            )
        
        return {"loss" : loss}
    
    def validation_step(self, batch, batch_idx):
        # mod_quant = self.quant
        mod_quant = self
        train_embeddings, train_labels = self.get_all_embeddings(self.train_set, mod_quant)
        test_embeddings, test_labels = self.get_all_embeddings(self.test_set, mod_quant)
        train_labels = train_labels.squeeze(1)
        test_labels = test_labels.squeeze(1)
        # print("Computing accuracy")
        accuracies = self.accuracy_calculator.get_accuracy(
            test_embeddings, train_embeddings, test_labels, train_labels, False
        )
        # print(accuracies)
        self.log("val_acc", accuracies["precision_at_1"])
        # print("Test set accuracy (Precision@1) = {}".format(accuracies["precision_at_1"]))

    # def test_step(self, batch, batch_idx):
    #     train_embeddings, train_labels = self.get_all_embeddings(train_set, model)
    #     test_embeddings, test_labels = self.get_all_embeddings(test_set, model)
    #     train_labels = train_labels.squeeze(1)
    #     test_labels = test_labels.squeeze(1)
    #     print("Computing accuracy")
    #     accuracies = accuracy_calculator.get_accuracy(
    #         test_embeddings, train_embeddings, test_labels, train_labels, False
    #     )
    #     print("Test set accuracy (Precision@1) = {}".format(accuracies["precision_at_1"]))

    def configure_optimizers(self):
        # return optim.Adam(self.parameters(), lr=0.0001)
        
        return optim.AdamW(self.parameters(), lr=self.lr, amsgrad=False)
        # return {"lr_scheduler" : , "optimizer" : }




### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###
# class Net(nn.Module):
#     def __init__(self):
#         super(Net, self).__init__()
#         self.conv1 = nn.Conv2d(1, 32, 3, 1) # [N, 30, 30, 32]
#         self.conv2 = nn.Conv2d(32, 64, 3, 1) # [N, 28, 28, 64]
#         self.dropout1 = nn.Dropout2d(0.25)
#         self.dropout2 = nn.Dropout2d(0.5)
#         self.fc1 = nn.Linear(9216, 128)

#     def forward(self, x):
#         x = self.conv1(x)# [N, 30, 30, 32]
#         x = F.relu(x)# [N, 30, 30, 32]
#         x = self.conv2(x)# [N, 28, 28, 64]
#         x = F.relu(x)# [N, 28, 28, 64]
#         x = F.max_pool2d(x, 2)
#         x = self.dropout1(x)
#         x = torch.flatten(x, 1)
#         x = self.fc1(x)
#         return x


### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###
# def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):
#     model.train()
#     for batch_idx, (data, labels) in enumerate(train_loader):
#         data, labels = data.to(device), labels.to(device)
#         optimizer.zero_grad()
#         embeddings = model(data)
#         Console().rule(title=f"EMBEDDINGS shape ===> {embeddings.shape}", style="bold magenta")
#         indices_tuple = mining_func(embeddings, labels)
#         Console().rule(title=f"INDICES shape ===> {indices_tuple}", style="bold magenta")
#         loss = loss_func(embeddings, labels, indices_tuple)
#         loss.backward()
#         optimizer.step()
#         if batch_idx % 20 == 0:
#             print(
#                 "Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}".format(
#                     epoch, batch_idx, loss, mining_func.num_triplets
#                 )
#             )


### convenient function from pytorch-metric-learning ###
# def get_all_embeddings(dataset, model):
#     tester = testers.BaseTester()
#     return tester.get_all_embeddings(dataset, model)


### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###
# def test(train_set, test_set, model, accuracy_calculator):
#     model.eval()
#     train_embeddings, train_labels = get_all_embeddings(train_set, model)
#     test_embeddings, test_labels = get_all_embeddings(test_set, model)
#     train_labels = train_labels.squeeze(1)
#     test_labels = test_labels.squeeze(1)
#     print("Computing accuracy")
#     accuracies = accuracy_calculator.get_accuracy(
#         test_embeddings, train_embeddings, test_labels, train_labels, False
#     )
#     print("Test set accuracy (Precision@1) = {}".format(accuracies["precision_at_1"]))


# device = torch.device("cuda")

transform = transforms.Compose(
    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]
)

batch_size = 512

dataset1 = datasets.MNIST(".", train=True, download=True, transform=transform)
dataset2 = datasets.MNIST(".", train=False, transform=transform)
train_loader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=True, num_workers=8)
test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)

# # model = Net().to(device)
# # optimizer = optim.Adam(model.parameters(), lr=0.01)
# # num_epochs = 3


# ### pytorch-metric-learning stuff ###
# # distance = distances.CosineSimilarity()
# # reducer = reducers.ThresholdReducer(low=0)
# # loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)
# # mining_func = miners.TripletMarginMiner(
# #     margin=0.2, distance=distance, type_of_triplets="semihard"
# # )
# # accuracy_calculator = AccuracyCalculator(include=("precision_at_1",), k=1)
# ### pytorch-metric-learning stuff ###


# # for epoch in range(1, num_epochs + 1):
# #     train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)
# #     test(dataset1, dataset2, model, accuracy_calculator)

# # Config dictionary that will be logged to W&B.

# # wandb.init()
# wandb.login()



# CONFIG = dict (
#     dataset = "/content/MNIST",
#     batch_size = batch_size,
#     epochs = 10,
#     precision = 16,
#     amp_backend = "native",
#     train_trf = transform,
#     test_trf = transform,
#     gpus = 1,
#     checkpoint_callback = ModelCheckpoint(monitor='val_acc',
#                                       save_top_k=1,
#                                       save_last=True,
#                                       save_weights_only=False,
#                                       filename='checkpoint/{epoch:03d}-{train_loss:.6f}-{val_acc:.6f}',
#                                       verbose=True,
#                                       mode='max'),
               
#     qat = QuantizationAwareTraining()

# )

# # checkpoint_callback = ModelCheckpoint(monitor='train_loss',
# #                                       save_top_k=1,
# #                                       save_last=True,
# #                                       save_weights_only=False,
# #                                       filename='checkpoint/{epoch:03d}-{train_loss:.4f}',
# #                                       verbose=True,
# #                                       mode='min')



# wandb_logger = WandbLogger(project='train-siamese', 
#                            config=CONFIG,
#                            group='MNIST', 
#                            job_type='Triplet loss + QAT',
#                            log_model="all")

# model = recognition_model(dataset1, dataset2)
# wandb_logger.watch(model, log="all")


# trainer = Trainer(max_epochs = CONFIG["epochs"], 
#                     precision=CONFIG["precision"], 
#                     amp_backend=CONFIG["amp_backend"], 
#                     gpus=CONFIG["gpus"],
#             # checkpoint_callback=checkpoint_callback,
#                     callbacks=[CONFIG["checkpoint_callback"], CONFIG["qat"]],
#                     logger=wandb_logger,
#                     weights_summary='top',)


# trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)
# # wandb_logger.unwatch(model)
# wandb.finish()

x,y = iter(test_loader).next()
print(y.dtype)

"""# Plotting some images"""

# In [107]: import torchvision

# # sample input (10 RGB images containing just Gaussian Noise)
# In [108]: batch_tensor = torch.randn(*(10, 3, 256, 256))   # (N, C, H, W)

# # make grid (2 rows and 5 columns) to display our 10 images
# In [109]: grid_img = torchvision.utils.make_grid(batch_tensor, nrow=5)

# # check shape
# In [110]: grid_img.shape
# Out[110]: torch.Size([3, 518, 1292])

# # reshape and plot (because MPL needs channel as the last dimension)
# In [111]: plt.imshow(grid_img.permute(1, 2, 0))
# Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
# Out[111]: <matplotlib.image.AxesImage at 0x7f62081ef080>

from torchvision.utils import make_grid
import matplotlib.pyplot as plt

batch = iter(train_loader).next()
grid_img = make_grid(batch[0][:100], nrow=20)
print(grid_img.shape) # [C, H, W]
plt.figure(figsize=(22, 10))
plt.imshow(grid_img.permute(1, 2, 0))

"""# Quantization Aware Training

## Generic Inference
"""

# trainer = Trainer(callbacks=[QuantizationAwareTraining()])
# qmodel = RegressionModel()
# trainer.fit(qmodel, ...)

# batch = iter(my_dataloader()).next()
# qmodel(qmodel.quant(batch[0]))

"""## Using In production (torchscript)"""

# tsmodel = qmodel.to_torchscript()
# tsmodel(tsmodel.quant(batch[0]))